{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "# BISINDO Sign Language Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Description\n",
        "\n",
        "This project is a final project for \"Rekayasa Sistem Berbasis Pengetahuan (RSBP)\". This project is a web-based application that can translate BISINDO sign language to Indonesian language. This application is made to help people who are not familiar with BISINDO sign language to communicate with people who are deaf. </br>\n",
        "\n",
        "## Appoarch Method\n",
        "\n",
        "This project employs the Object Detection method to identify hand gestures, utilizing a customized YOLO v8 dataset model. This model is designed to detect various hand gestures and provide the bounding box coordinates delineating these gestures. Once the bounding box is identified, the corresponding region of interest (ROI) containing the hand gesture is cropped. Subsequently, this cropped image undergoes further processing through a Convolutional Neural Network (CNN) model for precise classification of the detected hand gesture. The CNN model's output yields the specific label corresponding to the gesture identified. To enhance user experience, these labels are translated into Indonesian using a Rule-Based method before being displayed on the screen interface. </br>\n",
        "\n",
        "In terms of visualization, the project harnesses MediaPipe, a tool enabling the drawing of hand gesture bounding boxes and their associated labels directly on the screen. This integration ensures users can visually comprehend the detected gestures in real-time with graphical representations. </br>\n",
        "\n",
        "Moreover, the project is built as a web-based application using Flask, allowing seamless accessibility and interaction through a web interface. This framework facilitates the deployment of the hand gesture detection system within a browser, ensuring ease of use across various devices without necessitating complex setups or installations. </br>\n",
        "\n",
        "## Visual Demo\n",
        "\n",
        "### Dashboard\n",
        "![dashboard](../img/image.png)</br>\n",
        "\n",
        "### Stream Youtube Detection\n",
        "![yt](../img/image-2.png)</br>\n",
        "\n",
        "### Camera Detection\n",
        "![run](../img/image-1.png)</br>\n",
        "\n",
        "## Step by Step Method\n",
        "- Train the model using YOLOv8 with custom dataset\n",
        "- Create a CNN model to classify the cropped image\n",
        "- Create a Flask app to run the model\n",
        "- Create a web interface using HTML and CSS\n",
        "- Create feature interaction using Javascript \n",
        "\n",
        "## Features\n",
        "- Detect hand gesture from Camera\n",
        "- Detect hand gesture from Youtube video\n",
        "- Switch on/off the detection\n",
        "- Switch on/off the landmark\n",
        "- Flip the video\n",
        "- Modify Confidence Threshold\n",
        "- The result accumulates the detected words over 10 sequential frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "d2185ab5-0f43-47b6-b675-937ee56331d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr 18 03:24:38 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 537.70                 Driver Version: 537.70       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   40C    P4              12W /  35W |      0MiB /  8188MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import OS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "c0bb0d9a-2cd3-4bea-d38a-070b74a5a89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\train\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "### Yolo Instalation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "6193e25a-2cfd-4d96-fe9f-769add6166f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.196  Python-3.11.4 torch-2.2.2+cpu CPU (AMD Ryzen 7 7840HS w/ Radeon 780M Graphics)\n",
            "Setup complete  (16 CPUs, 15.2 GB RAM, 183.9/474.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### Import Dataset Form Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "eb8bcd99-cea8-48a1-bf11-7a37f2aa7018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train/datasets'\n",
            "c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "%mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "%pip install roboflow --quiet\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"moOAxzoPZOtIzhyyco0r\")\n",
        "project = rf.workspace(\"bisindo-qndjb\").project(\"bisindov2\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "7f5ea4f9-6e7d-4470-8209-9a253786cd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\train\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args='yolo task=detect mode=train model=yolov8s.pt data=c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train\\\\BISINDOv2-1/data.yaml epochs=25 imgsz=800 plots=True', returncode=1)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True\n",
        "\n",
        "import subprocess\n",
        "\n",
        "command = \"yolo task=detect mode=train model=yolov8s.pt data={}/data.yaml epochs=25 imgsz=800 plots=True\".format(dataset.location)\n",
        "subprocess.run(command, shell=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MScstfHhArr",
        "outputId": "7865d222-af3a-49bd-9aa7-3816872815c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parameter format not correct - \"runs\".\n"
          ]
        }
      ],
      "source": [
        "%ls {HOME}/runs/detect/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "_J35i8Ofhjxa",
        "outputId": "762ae444-f7c9-42f5-cd2c-8ea7facee223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\train\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train\\\\runs\\\\detect\\\\train\\\\confusion_matrix.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{HOME}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHOME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdetect\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mconfusion_matrix.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train\\\\runs\\\\detect\\\\train\\\\confusion_matrix.png'"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}\\\\runs\\\\detect\\\\train\\\\confusion_matrix.png', width=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "A-urTWUkhRmn",
        "outputId": "58b67f20-8844-43f4-ff41-c8c498036fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\train\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train/runs/detect/train/results.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{HOME}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHOME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/runs/detect/train/results.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
            "File \u001b[1;32mc:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train/runs/detect/train/results.png'"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/configuration_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "### Validate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "88f5e42d-e10d-45db-c578-7c85f8667c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 420, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 97, in __init__\n",
            "    self._load(model, task)\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 149, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 628, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 567, in torch_safe_load\n",
            "    return torch.load(file, map_location='cpu'), file  # load\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\torch\\serialization.py\", line 998, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\torch\\serialization.py\", line 445, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\srita\\OneDrive\\Desktop\\Sign_Language_Translator_Web_App_Yolo_Flask\\myenv\\Lib\\site-packages\\torch\\serialization.py\", line 426, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\srita\\\\OneDrive\\\\Desktop\\\\Sign_Language_Translator_Web_App_Yolo_Flask\\\\train\\\\runs\\\\detect\\\\train\\\\weights\\\\best.pt'\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "### Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjc1ctZykYuf",
        "outputId": "f400774d-404b-4fef-ef58-796fc4fd522e"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "### Run Model on CAMERA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As_cl3OkQWQ1",
        "outputId": "759e88f3-c3b8-474f-d217-35765bd81d06"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model=D:/Kuliah/\\(2023\\)S5-RSBP/FP/runs/detect/train/weights/best.pt source=0 show=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Result\n",
        "\n",
        "### Confussion Matrix\n",
        "![dashboard](../img/confussion_matrix.png)</br>\n",
        "\n",
        "### Result Curve\n",
        "![dashboard](../img/result.png)</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Flask Web Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Requirements Dependencies\n",
        "To install the Python requirements from the `requirements.txt` file, run the following command in your terminal or command prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create new app.py file for main program\n",
        "Import libray that needed for this project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import time\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "\n",
        "import cv2\n",
        "from flask import Flask, render_template, request, Response, session, redirect, url_for\n",
        "\n",
        "from flask_socketio import SocketIO\n",
        "import yt_dlp as youtube_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation for each library:\n",
        "- ultralytics.YOLO: Used for real-time object detection.\n",
        "- time: Handles time-related functions.\n",
        "- numpy as np: Supports numerical computations and arrays.\n",
        "- mediapipe as mp: Facilitates various media processing tasks like object detection and hand tracking.\n",
        "- cv2: Offers tools for computer vision, image, and video processing.\n",
        "- Flask: A lightweight web framework for building web applications.\n",
        "- Flask_socketio and SocketIO: Enables WebSocket support for real-time communication in Flask.\n",
        "- yt_dlp as youtube_dl: Used to stream media content from various streaming sites, like YouTube."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_object_detection = YOLO(\".\\bisindo.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Function for Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show(self, url):\n",
        "        print(url)\n",
        "        self._preview = False\n",
        "        self._flipH = False\n",
        "        self._detect = False\n",
        "        self._mediaPipe = False\n",
        "\n",
        "        self._confidence = 75.0\n",
        "        ydl_opts = {\n",
        "            \"quiet\": True,\n",
        "            \"no_warnings\": True,\n",
        "            \"format\": \"best\",\n",
        "            \"forceurl\": True,\n",
        "        }\n",
        "\n",
        "        if url == '0':\n",
        "            cap = cv2.VideoCapture(0)\n",
        "        else:\n",
        "            \n",
        "            ydl = youtube_dl.YoutubeDL(ydl_opts)\n",
        "\n",
        "            info = ydl.extract_info(url, download=False)\n",
        "            url = info[\"url\"]\n",
        "\n",
        "            cap = cv2.VideoCapture(url)\n",
        "\n",
        "        while True:\n",
        "            if self._preview:\n",
        "                if stop_flag:\n",
        "                    print(\"Process Stopped\")\n",
        "                    return\n",
        "\n",
        "                grabbed, frame = cap.read()\n",
        "                if not grabbed:\n",
        "                    break\n",
        "                if self.flipH:\n",
        "                    frame = cv2.flip(frame, 1)\n",
        "\n",
        "                if self.detect:\n",
        "                    frame_yolo = frame.copy()\n",
        "                    results_yolo = model_object_detection.predict(frame_yolo, conf=self._confidence / 100)\n",
        "\n",
        "                    frame_yolo, labels = results_yolo[0].plot()\n",
        "                    list_labels = []\n",
        "                    # labels_confidences\n",
        "                    for label in labels:\n",
        "                        confidence = label.split(\" \")[-1]\n",
        "                        label = (label.split(\" \"))[:-1]\n",
        "                        label = \" \".join(label)\n",
        "                        list_labels.append(label)\n",
        "                        list_labels.append(confidence)\n",
        "                        socketio.emit('label', list_labels)\n",
        "\n",
        "                if self.mediaPipe:\n",
        "                    # Convert the image to RGB for processing with MediaPipe\n",
        "                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results = self.hands.process(image)\n",
        "                    \n",
        "                    if results.multi_hand_landmarks:\n",
        "                        for hand_landmarks in results.multi_hand_landmarks:\n",
        "                            mp.solutions.drawing_utils.draw_landmarks(\n",
        "                                frame,\n",
        "                                hand_landmarks,\n",
        "                                self.mp_hands.HAND_CONNECTIONS,\n",
        "                                landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(255, 0, 0), thickness=4, circle_radius=3),\n",
        "                                connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2), \n",
        "                            )\n",
        "\n",
        "                frame = cv2.imencode(\".jpg\", frame)[1].tobytes()\n",
        "                yield ( \n",
        "                    b'--frame\\r\\n'\n",
        "                    b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n'\n",
        "                )\n",
        "            else:\n",
        "                snap = np.zeros((\n",
        "                    1000,\n",
        "                    1000\n",
        "                ), np.uint8)\n",
        "                label = \"Streaming Off\"\n",
        "                H, W = snap.shape\n",
        "                font = cv2.FONT_HERSHEY_PLAIN\n",
        "                color = (255, 255, 255)\n",
        "                cv2.putText(snap, label, (W//2 - 100, H//2),\n",
        "                            font, 2, color, 2)\n",
        "                frame = cv2.imencode(\".jpg\", snap)[1].tobytes()\n",
        "                yield (b'--frame\\r\\n'\n",
        "                       b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation for each object:\n",
        "- preview(): Displays the video stream on the web interface.\n",
        "- flipH(): Flips the video horizontally.\n",
        "- detect(): Detects using Yolo model the hand gesture from the video stream.\n",
        "- mediaPipe(): Draws the hand gesture landmark on the video stream.\n",
        "\n",
        "### Explanation for flow of the program:\n",
        "- If user input is \"camera\", the program will run the camera detection.\n",
        "- If user input is \"url youtube video\", the program will run the youtube detection.\n",
        "- If user activate the preview, the program will run the video stream/camera.\n",
        "- If user activate the detection, the program will run the detection.\n",
        "- If user activate the landmark, the program will run the landmark.\n",
        "- If user activate the flip, video will be flipped.\n",
        "- Threshold is used to set the minimum confidence threshold of the detection.\n",
        "- If the preview is not activated, the program will show `streaming off` label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integration in HTML, CSS, and Javascript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In CSS file, create a style for the stream and output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "#container {\n",
              "    width: 100%;\n",
              "    height: 586px;\n",
              "    border: 8px #2c374a solid;\n",
              "    background-color: #0F172A;\n",
              "    border-radius: 5px;\n",
              "}\n",
              "\n",
              "#videoElement {\n",
              "    height: 570px;\n",
              "    width: 100%;\n",
              "    background-color: #0F172A;\n",
              "\n",
              "    display: block;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "}\n",
              "\n",
              "#terminal {\n",
              "    border-radius: 5px;\n",
              "    border: 5px #1C2637 solid;\n",
              "    font-family: monospace;\n",
              "    font-size: 12px;\n",
              "    background-color: #0F172A;\n",
              "    height: 490px;\n",
              "    overflow-y: scroll;\n",
              "}\n",
              "<style/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "%%html\n",
        "<style>\n",
        "#container {\n",
        "    width: 100%;\n",
        "    height: 586px;\n",
        "    border: 8px #2c374a solid;\n",
        "    background-color: #0F172A;\n",
        "    border-radius: 5px;\n",
        "}\n",
        "\n",
        "#videoElement {\n",
        "    height: 570px;\n",
        "    width: 100%;\n",
        "    background-color: #0F172A;\n",
        "\n",
        "    display: block;\n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "}\n",
        "\n",
        "#terminal {\n",
        "    border-radius: 5px;\n",
        "    border: 5px #1C2637 solid;\n",
        "    font-family: monospace;\n",
        "    font-size: 12px;\n",
        "    background-color: #0F172A;\n",
        "    height: 490px;\n",
        "    overflow-y: scroll;\n",
        "}\n",
        "<style/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In Javascript, create a function needed for the web interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For Camera or Video Button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
              "<script>\n",
              "function startCamera() {\n",
              "    var url = '0';\n",
              "    $('#urlForm').attr('action', '/index'); \n",
              "    $('#urlForm').attr('method', 'POST'); \n",
              "    $('#urlForm').find('#url').val(url);\n",
              "    $('#urlForm').submit();\n",
              "}\n",
              "\n",
              "function startVideo() {\n",
              "    var url = $('#url').val();\n",
              "    $('#urlForm').attr('action', '/index'); \n",
              "    $('#urlForm').attr('method', 'POST'); \n",
              "    $('#urlForm').find('#url').val(url);\n",
              "    $('#urlForm').submit();\n",
              "}\n",
              "<script/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
        "<script>\n",
        "function startCamera() {\n",
        "    var url = '0';\n",
        "    $('#urlForm').attr('action', '/index'); \n",
        "    $('#urlForm').attr('method', 'POST'); \n",
        "    $('#urlForm').find('#url').val(url);\n",
        "    $('#urlForm').submit();\n",
        "}\n",
        "\n",
        "function startVideo() {\n",
        "    var url = $('#url').val();\n",
        "    $('#urlForm').attr('action', '/index'); \n",
        "    $('#urlForm').attr('method', 'POST'); \n",
        "    $('#urlForm').find('#url').val(url);\n",
        "    $('#urlForm').submit();\n",
        "}\n",
        "<script/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For terminal output, socket, and final output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
              "<script>\n",
              "var socket = io.connect('http://127.0.0.1:5000/');\n",
              "\n",
              "let consecutiveWords = [];\n",
              "let finalSentence = \"\";\n",
              "let wordCounter = 0;\n",
              "\n",
              "function appendToTerminal(message) {\n",
              "    var terminal = document.getElementById(\"terminal\");\n",
              "    var p = document.createElement(\"p\");\n",
              "    p.innerHTML = `<table class=\"table table-striped text-center\" style=\"border: none;\">\n",
              "                    <tr class=\"row\">\n",
              "                        <td class=\"col-md-6\" style=\"color: #01ECEC; border: none;\">${message[0]}</td>\n",
              "                        <td class=\"col-md-6\" style=\"color: #01ECEC; border: none;\">${message[1]}</td>\n",
              "                    </tr>\n",
              "                </table>`;\n",
              "    terminal.appendChild(p);\n",
              "    terminal.scrollTop = terminal.scrollHeight;\n",
              "\n",
              "    if (consecutiveWords.length === 0 || consecutiveWords[consecutiveWords.length - 1] === message[0]) {\n",
              "        consecutiveWords.push(message[0]);\n",
              "        wordCounter++; \n",
              "    } else {\n",
              "        consecutiveWords = [message[0]];\n",
              "        wordCounter = 1;\n",
              "    }\n",
              "\n",
              "    if (wordCounter >= 10) {\n",
              "        finalSentence += (finalSentence.length > 0 ? \" \" : \"\") + consecutiveWords[0];\n",
              "        document.getElementById(\"finalSentencePara\").innerText = finalSentence;\n",
              "        consecutiveWords = [];\n",
              "        wordCounter = 0;\n",
              "    }\n",
              "}\n",
              "\n",
              "socket.on(\"label\", (data) => {\n",
              "    appendToTerminal(data);\n",
              "});\n",
              "<script/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
        "<script>\n",
        "var socket = io.connect('http://127.0.0.1:5000/');\n",
        "\n",
        "let consecutiveWords = [];\n",
        "let finalSentence = \"\";\n",
        "let wordCounter = 0;\n",
        "\n",
        "function appendToTerminal(message) {\n",
        "    var terminal = document.getElementById(\"terminal\");\n",
        "    var p = document.createElement(\"p\");\n",
        "    p.innerHTML = `<table class=\"table table-striped text-center\" style=\"border: none;\">\n",
        "                    <tr class=\"row\">\n",
        "                        <td class=\"col-md-6\" style=\"color: #01ECEC; border: none;\">${message[0]}</td>\n",
        "                        <td class=\"col-md-6\" style=\"color: #01ECEC; border: none;\">${message[1]}</td>\n",
        "                    </tr>\n",
        "                </table>`;\n",
        "    terminal.appendChild(p);\n",
        "    terminal.scrollTop = terminal.scrollHeight;\n",
        "\n",
        "    if (consecutiveWords.length === 0 || consecutiveWords[consecutiveWords.length - 1] === message[0]) {\n",
        "        consecutiveWords.push(message[0]);\n",
        "        wordCounter++; \n",
        "    } else {\n",
        "        consecutiveWords = [message[0]];\n",
        "        wordCounter = 1;\n",
        "    }\n",
        "\n",
        "    if (wordCounter >= 10) {\n",
        "        finalSentence += (finalSentence.length > 0 ? \" \" : \"\") + consecutiveWords[0];\n",
        "        document.getElementById(\"finalSentencePara\").innerText = finalSentence;\n",
        "        consecutiveWords = [];\n",
        "        wordCounter = 0;\n",
        "    }\n",
        "}\n",
        "\n",
        "socket.on(\"label\", (data) => {\n",
        "    appendToTerminal(data);\n",
        "});\n",
        "<script/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Integration with SocketIO:\n",
        "\n",
        "- Listens for data labeled as \"label\" from a SocketIO connection.\n",
        "- Calls appendToTerminal() to display the received data in the terminal and potentially update an advertisement based on the data.\n",
        "\n",
        "Function appendToTerminal(message):\n",
        "\n",
        "- Takes a message as input.\n",
        "- Adds a table with two columns to the terminal for displaying the message.\n",
        "- Keeps track of consecutive words and their counts.\n",
        "- Constructs a final sentence if a word appears more than ten times consecutively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For Toggle Button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
              "<script>\n",
              "function toggleHSwitch() {\n",
              "    var switchElement = $(\"#flip-horizontal\");\n",
              "    var switchIsOn = switchElement.is(\":checked\");\n",
              "\n",
              "    if (switchIsOn) {\n",
              "        console.log(\"SWITCH ON\")\n",
              "        $.getJSON(\"/request_flipH_switch\", function (data) {\n",
              "            console.log(\"Switch on request sent.\");\n",
              "        });\n",
              "    } else {\n",
              "        console.log(\"SWITCH OFF\")\n",
              "        $.getJSON(\"/request_flipH_switch\", function (data) {\n",
              "            console.log(\"Switch off request sent.\");\n",
              "        });\n",
              "    }\n",
              "}\n",
              "\n",
              "function toggleMediaPipeSwitch() {\n",
              "    var switchElement = $(\"#mediapipe\");\n",
              "    var switchIsOn = switchElement.is(\":checked\");\n",
              "\n",
              "    if (switchIsOn) {\n",
              "        console.log(\"SWITCH ON\")\n",
              "        $.getJSON(\"/request_mediapipe_switch\", function (data) {\n",
              "            console.log(\"Switch on request sent.\");\n",
              "        });\n",
              "    } else {\n",
              "        console.log(\"SWITCH OFF\")\n",
              "        $.getJSON(\"/request_mediapipe_switch\", function (data) {\n",
              "            console.log(\"Switch off request sent.\");\n",
              "        });\n",
              "    }\n",
              "}\n",
              "\n",
              "function toggleDetSwitch() {\n",
              "\n",
              "    var switchElement = $(\"#run_detection\");\n",
              "    var switchIsOn = switchElement.is(\":checked\");\n",
              "\n",
              "    if (switchIsOn) {\n",
              "        console.log(\"SWITCH ON\")\n",
              "        $.getJSON(\"/request_run_model_switch\", function (data) {\n",
              "            console.log(\"Switch on request sent.\");\n",
              "        });\n",
              "    } else {\n",
              "        console.log(\"SWITCH OFF\")\n",
              "        $.getJSON(\"/request_run_model_switch\", function (data) {\n",
              "            console.log(\"Switch off request sent.\");\n",
              "        });\n",
              "    }\n",
              "}\n",
              "\n",
              "function toggleOffSwitch() {\n",
              "    var switchElement = $(\"#turn_off\");\n",
              "    var switchIsOn = switchElement.is(\":checked\");\n",
              "\n",
              "    if (switchIsOn) {\n",
              "        console.log(\"Camera ON\")\n",
              "        $.getJSON(\"/request_preview_switch\", function (data) {\n",
              "            console.log(\"Switch on request sent.\");\n",
              "        });\n",
              "    } else {\n",
              "        console.log(\"Camera OFF\")\n",
              "        $.getJSON(\"/request_preview_switch\", function (data) {\n",
              "            console.log(\"Switch off request sent.\");\n",
              "        });\n",
              "    }\n",
              "}\n",
              "<script/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
        "<script>\n",
        "function toggleHSwitch() {\n",
        "    var switchElement = $(\"#flip-horizontal\");\n",
        "    var switchIsOn = switchElement.is(\":checked\");\n",
        "\n",
        "    if (switchIsOn) {\n",
        "        console.log(\"SWITCH ON\")\n",
        "        $.getJSON(\"/request_flipH_switch\", function (data) {\n",
        "            console.log(\"Switch on request sent.\");\n",
        "        });\n",
        "    } else {\n",
        "        console.log(\"SWITCH OFF\")\n",
        "        $.getJSON(\"/request_flipH_switch\", function (data) {\n",
        "            console.log(\"Switch off request sent.\");\n",
        "        });\n",
        "    }\n",
        "}\n",
        "\n",
        "function toggleMediaPipeSwitch() {\n",
        "    var switchElement = $(\"#mediapipe\");\n",
        "    var switchIsOn = switchElement.is(\":checked\");\n",
        "\n",
        "    if (switchIsOn) {\n",
        "        console.log(\"SWITCH ON\")\n",
        "        $.getJSON(\"/request_mediapipe_switch\", function (data) {\n",
        "            console.log(\"Switch on request sent.\");\n",
        "        });\n",
        "    } else {\n",
        "        console.log(\"SWITCH OFF\")\n",
        "        $.getJSON(\"/request_mediapipe_switch\", function (data) {\n",
        "            console.log(\"Switch off request sent.\");\n",
        "        });\n",
        "    }\n",
        "}\n",
        "\n",
        "function toggleDetSwitch() {\n",
        "\n",
        "    var switchElement = $(\"#run_detection\");\n",
        "    var switchIsOn = switchElement.is(\":checked\");\n",
        "\n",
        "    if (switchIsOn) {\n",
        "        console.log(\"SWITCH ON\")\n",
        "        $.getJSON(\"/request_run_model_switch\", function (data) {\n",
        "            console.log(\"Switch on request sent.\");\n",
        "        });\n",
        "    } else {\n",
        "        console.log(\"SWITCH OFF\")\n",
        "        $.getJSON(\"/request_run_model_switch\", function (data) {\n",
        "            console.log(\"Switch off request sent.\");\n",
        "        });\n",
        "    }\n",
        "}\n",
        "\n",
        "function toggleOffSwitch() {\n",
        "    var switchElement = $(\"#turn_off\");\n",
        "    var switchIsOn = switchElement.is(\":checked\");\n",
        "\n",
        "    if (switchIsOn) {\n",
        "        console.log(\"Camera ON\")\n",
        "        $.getJSON(\"/request_preview_switch\", function (data) {\n",
        "            console.log(\"Switch on request sent.\");\n",
        "        });\n",
        "    } else {\n",
        "        console.log(\"Camera OFF\")\n",
        "        $.getJSON(\"/request_preview_switch\", function (data) {\n",
        "            console.log(\"Switch off request sent.\");\n",
        "        });\n",
        "    }\n",
        "}\n",
        "<script/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For HTML, integrate the Javascript function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For Camera and Terminal Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!-- Video -->\n",
              "<div class=\"col-span-8 mx-4 mt-3\">\n",
              "    <div id=\"container\">\n",
              "        <img class=\"center\" src=\"/video_feed\" id=\"videoElement\">\n",
              "    </div>\n",
              "</div>\n",
              "\n",
              "<!-- Terminal -->\n",
              "<div class=\"col-span-2 mr-4\">\n",
              "    <h2 class=\"border-b border-slate-800 py-4 mb-4 text-3xl flex justify-end font-bold leading-none tracking-tight md:text-4xl lg:text-4xl text-cyan-100 \">Output</h1>\n",
              "    <div id=\"terminal\" class=\"w-full\"></div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "html_code = '''\n",
        "<!-- Video -->\n",
        "<div class=\"col-span-8 mx-4 mt-3\">\n",
        "    <div id=\"container\">\n",
        "        <img class=\"center\" src=\"/video_feed\" id=\"videoElement\">\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "<!-- Terminal -->\n",
        "<div class=\"col-span-2 mr-4\">\n",
        "    <h2 class=\"border-b border-slate-800 py-4 mb-4 text-3xl flex justify-end font-bold leading-none tracking-tight md:text-4xl lg:text-4xl text-cyan-100 \">Output</h1>\n",
        "    <div id=\"terminal\" class=\"w-full\"></div>\n",
        "</div>\n",
        "'''\n",
        "display(HTML(html_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For toggle switch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<div class=\"flex gap-3 mb-4\">\n",
              "    <label class=\"switch\">\n",
              "        <input id=\"turn_off\" value=\"1\" name=\"turn_off\" type=\"checkbox\" onclick=\"toggleOffSwitch()\"/>\n",
              "        <span class=\"slider round\"></span>\n",
              "    </label>\n",
              "    <label for=\"turn_off\" class=\"form-label text-cyan-500\">Show Video</label><br>\n",
              "</div>\n",
              "<div class=\"flex gap-3 mb-4\">\n",
              "    <label class=\"switch\">\n",
              "        <input id=\"run_detection\" value=\"0\" name=\"run_detection\" type=\"checkbox\"\n",
              "               onclick=\"toggleDetSwitch()\"/>\n",
              "        <span class=\"slider round\"></span>\n",
              "    </label>\n",
              "    <label for=\"run_detection\" class=\"form-label text-cyan-500\">Run Detection</label><br>\n",
              "</div>\n",
              "<div class=\"flex gap-3 mb-4\">\n",
              "    <label class=\"switch\">\n",
              "        <input id=\"mediapipe\" value=\"0\" name=\"mediapipe\" type=\"checkbox\"\n",
              "               onclick=\"toggleMediaPipeSwitch()\"/>\n",
              "        <span class=\"slider round\"></span>\n",
              "    </label>\n",
              "    <label for=\"mediapipe\" class=\"form-label text-cyan-500\">Show Landmark</label><br>\n",
              "</div>\n",
              "<div class=\"flex gap-3 mb-4\">\n",
              "    <label class=\"switch\">\n",
              "        <input id=\"flip-horizontal\" value=\"0\" name=\"flip-horizontal\" type=\"checkbox\"\n",
              "               onclick=\"toggleHSwitch()\"/>\n",
              "        <span class=\"slider round\"></span>\n",
              "    </label>\n",
              "    <label for=\"flip-horizontal\" class=\"form-label text-cyan-500\">Flip Video</label><br>\n",
              "</div>\n",
              "\n",
              "<div class=\"gap-3 py-4 text-center border-b border-slate-800 mb-5\">\n",
              "    <form action=\"/\" method=\"POST\" style=\"text-align: center;\" class=\"mb-4\" >\n",
              "        <label for=\"slider\" class=\"form-label text-cyan-500\">Confidence Threshold</label>\n",
              "        <input type=\"range\" id=\"slider\" name=\"slider\" min=\"1\" max=\"100\">\n",
              "    </form>\n",
              "    <input type=\"hidden\" id=\"sliderValue\" name=\"sliderValue\" value=\"75\">\n",
              "    <span class=\"rounded-lg py-2 px-3 bg-slate-800 text-cyan-500\" id=\"conf_display\">75</span>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "html_code = '''\n",
        "<div class=\"flex gap-3 mb-4\">\n",
        "    <label class=\"switch\">\n",
        "        <input id=\"turn_off\" value=\"1\" name=\"turn_off\" type=\"checkbox\" onclick=\"toggleOffSwitch()\"/>\n",
        "        <span class=\"slider round\"></span>\n",
        "    </label>\n",
        "    <label for=\"turn_off\" class=\"form-label text-cyan-500\">Show Video</label><br>\n",
        "</div>\n",
        "<div class=\"flex gap-3 mb-4\">\n",
        "    <label class=\"switch\">\n",
        "        <input id=\"run_detection\" value=\"0\" name=\"run_detection\" type=\"checkbox\"\n",
        "               onclick=\"toggleDetSwitch()\"/>\n",
        "        <span class=\"slider round\"></span>\n",
        "    </label>\n",
        "    <label for=\"run_detection\" class=\"form-label text-cyan-500\">Run Detection</label><br>\n",
        "</div>\n",
        "<div class=\"flex gap-3 mb-4\">\n",
        "    <label class=\"switch\">\n",
        "        <input id=\"mediapipe\" value=\"0\" name=\"mediapipe\" type=\"checkbox\"\n",
        "               onclick=\"toggleMediaPipeSwitch()\"/>\n",
        "        <span class=\"slider round\"></span>\n",
        "    </label>\n",
        "    <label for=\"mediapipe\" class=\"form-label text-cyan-500\">Show Landmark</label><br>\n",
        "</div>\n",
        "<div class=\"flex gap-3 mb-4\">\n",
        "    <label class=\"switch\">\n",
        "        <input id=\"flip-horizontal\" value=\"0\" name=\"flip-horizontal\" type=\"checkbox\"\n",
        "               onclick=\"toggleHSwitch()\"/>\n",
        "        <span class=\"slider round\"></span>\n",
        "    </label>\n",
        "    <label for=\"flip-horizontal\" class=\"form-label text-cyan-500\">Flip Video</label><br>\n",
        "</div>\n",
        "\n",
        "<div class=\"gap-3 py-4 text-center border-b border-slate-800 mb-5\">\n",
        "    <form action=\"/\" method=\"POST\" style=\"text-align: center;\" class=\"mb-4\" >\n",
        "        <label for=\"slider\" class=\"form-label text-cyan-500\">Confidence Threshold</label>\n",
        "        <input type=\"range\" id=\"slider\" name=\"slider\" min=\"1\" max=\"100\">\n",
        "    </form>\n",
        "    <input type=\"hidden\" id=\"sliderValue\" name=\"sliderValue\" value=\"75\">\n",
        "    <span class=\"rounded-lg py-2 px-3 bg-slate-800 text-cyan-500\" id=\"conf_display\">75</span>\n",
        "</div>\n",
        "'''\n",
        "display(HTML(html_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For Final Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<div>\n",
              "    <p id=\"finalSentencePara\" class=\"text-cyan-200 mt-4 text-center\">\n",
              "    </p>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "html_code = '''\n",
        "<div>\n",
        "    <p id=\"finalSentencePara\" class=\"text-cyan-200 mt-4 text-center\">\n",
        "    </p>\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML(html_code))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
